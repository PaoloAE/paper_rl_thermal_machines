{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Harmonic Oscillator Heat Engine\n",
    "Optimize the output power of a heat engine based on a quantum harmonic oscillator (see section IVc of manuscript or [this](https://doi.org/10.1088/1367-2630/8/5/083) reference). The Hamiltonian of the system is:\n",
    "\\begin{equation}\n",
    "\t\\hat{H}[u(t)] = \\frac{1}{2m} \\hat{p}^2 + \\frac{1}{2}m (u(t)w_0)^2 \\hat{q}^2,\n",
    "\\end{equation}\n",
    "where $m$ is the mass of the system, $w_0$ is a fixed frequency and $\\hat{p}$ and $\\hat{q}$ are the momentum and position operators. The single continuous control parameter is $u(t)$. \n",
    "The coupling to the baths is described using the Lindblad master equation [see Eq. (9) of the manuscript]. The Lindblad operators and corresponding rates are gived by\n",
    "\\begin{align}\n",
    "\t\\hat{A}^{(\\alpha)}_{+,u(t)} &= \\hat{a}_{u(t)}^\\dagger, & \\gamma^{(\\alpha)}_{+,u(t)} &= \\Gamma_\\alpha \\,n(\\beta_\\alpha u(t)\\omega_0), \\\\\n",
    "    \\hat{A}^{(\\alpha)}_{-,u(t)} &= \\hat{a}_{u(t)}, & \\gamma^{(\\alpha)}_{-,u(t)} &= \\Gamma_\\alpha[1+ n(\\beta_\\alpha u(t) \\omega_0 )],\n",
    "\\end{align}\n",
    "where $\\hat{a}_{u(t)}=(1/\\sqrt{2})\\sqrt{m\\omega_0 u(t)}\\,\\hat{q} + i/\\sqrt{m\\omega_0 u(t)}\\,\\hat{p}$ and $\\hat{a}_{u(t)}^\\dagger$ are respectively the (control dependent) lowering and raising operators, $\\Gamma_\\alpha$ are constant rates, $n(x)=(\\exp(x)-1)^{-1}$ is the Bose-Einstein distribution and $\\beta_\\alpha$ is the inverse temperature of bath $\\alpha$.\n",
    "#### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join('..','src'))\n",
    "import sac_tri\n",
    "import sac_tri_envs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup new Training\n",
    "The following codes initiates a new training session. All training logs, parameters and saved states will be stored under the ```data``` folder, within a folder with the current date and time. \n",
    "- ```env_params``` is a dictionary with the environment parameters.\n",
    "- ```training_hyperparams``` is a dictionary with training hyperparameters.\n",
    "- ```log_info``` is a dictionary that specifices which quantities to log.\n",
    "\n",
    "The parameters below were used to produce Fig. 5 of the manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEFT PANEL PARAMETERS\n",
    "wc = 1.\n",
    "wh = 1.99324\n",
    "LR = 0.001\n",
    "ALPHA_START = 50.\n",
    "ALPHA_DECAY = 24000\n",
    "INITIAL_RANDOM_STEPS = 5000\n",
    "\n",
    "#RIGHT PANEL PARAMETERS\n",
    "# wc = 0.7\n",
    "# wh = 3.\n",
    "# LR = 0.0005\n",
    "# ALPHA_START = 300.\n",
    "# ALPHA_DECAY = 48000\n",
    "# INITIAL_RANDOM_STEPS = 10000\n",
    "\n",
    "#THE FOLLOWING PARAMETERS ARE SHARED BY BOTH PANELS\n",
    "tc = 1./2.\n",
    "th = 4.98309\n",
    "w0 = 2.\n",
    "min_u = wc/w0 \n",
    "max_u = wh/w0 \n",
    "dt = 0.2\n",
    "\n",
    "env_params = {\n",
    "    \"g0\": 0.6,                                    #\\Gamma of bath 0\n",
    "    \"g1\": 0.6,                                    #\\Gamma of bath 1\n",
    "    \"b0\": 1./th,                                  #inverse temperature \\beta of bath 0\n",
    "    \"b1\": 1./tc,                                  #inverse temperature \\beta of bath 1\n",
    "    \"min_u\": min_u,                               #minimum value of action u\n",
    "    \"max_u\": max_u,                               #maximum value of action u\n",
    "    \"w0\": w0,                                     #\\omega_0\n",
    "    \"dt\": dt,                                     #timestep \\Delta t\n",
    "    \"reward_extra_coeff\": 10.                     #the reward is multiplied by this factor\n",
    "}  \n",
    "training_hyperparams = {\n",
    "    \"BATCH_SIZE\": 256,                            #batch size\n",
    "    \"LR\": LR,                                     #learning rate\n",
    "    \"ALPHA_START\": ALPHA_START,                   #initial value of SAC temperature\n",
    "    \"ALPHA_END\": 0.,                              #final value of SAC temperature\n",
    "    \"ALPHA_DECAY\": ALPHA_DECAY,                   #exponential decay of SAC temperature\n",
    "    \"REPLAY_MEMORY_SIZE\": 192000,                 #size of replay buffer\n",
    "    \"POLYAK\": 0.995,                              #polyak coefficient\n",
    "    \"LOG_STEPS\": 6000,                            #save logs and display training every number of steps\n",
    "    \"GAMMA\": 0.998,                               #RL discount factor\n",
    "    \"HIDDEN_SIZES\": (256,256),                    #size of hidden layers \n",
    "    \"SAVE_STATE_STEPS\": 80000,                    #saves complete state of trainig every number of steps\n",
    "    \"INITIAL_RANDOM_STEPS\": INITIAL_RANDOM_STEPS, #number of initial uniformly random steps\n",
    "    \"UPDATE_AFTER\": 1000,                         #start minimizing loss function after initial steps\n",
    "    \"UPDATE_EVERY\": 50,                           #performs this many updates every this many steps\n",
    "    \"USE_CUDA\": False                             #use cuda for computation\n",
    "}\n",
    "log_info = {\n",
    "    \"log_running_reward\": True,                   #log running reward \n",
    "    \"log_running_loss\": True,                     #log running loss\n",
    "    \"log_actions\": True,                          #log chosen actions\n",
    "    \"extra_str\": \"_harmonic_engine\"               #extra string to append to training folder\n",
    "}\n",
    "\n",
    "train = sac_tri.SacTrain()\n",
    "train.initialize_new_train(sac_tri_envs.HarmonicEngineLogState, env_params, training_hyperparams, log_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "Perform a given number of training steps. It can be run multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.train(300000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the State\n",
    "The full state of the training session is saved every ```SAVE_STATE_STEPS``` steps. Run this command if you wish to manually save the current state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.save_full_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Existing Training\n",
    "Any training session that was saved can be loaded specifying the training session folder in ```log_dir```. This will produce a new folder for logging with the current date-time. The following loads the latest save in a folder named ```\"2021_04_14-10_36_57_harmonic_engine\"```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"../data/2021_04_14-10_36_57_harmonic_engine/\"\n",
    "train = sac_tri.SacTrain()\n",
    "train.load_train(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train\n",
    "Perform a given number of training steps. It can be run multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.train(50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually changing the learning rate\n",
    "The following is NOT RECOMMENDED, since the change is not logged. However, it is possible to change the learning rate during training. The following changes the learning rate to 0.0001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in train.pi_optimizer.param_groups:\n",
    "    g['lr'] = 0.0001\n",
    "for g in train.q_optimizer.param_groups:\n",
    "    g['lr'] = 0.0001"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
