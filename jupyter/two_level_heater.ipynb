{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-Level System Heater\n",
    "## (Only used for testing)\n",
    "Optimize the output power dissipated into the environment (se [this](https://doi.org/10.1088/1367-2630/ab4dca) reference for details). The Hamiltonian of the system is:\n",
    "\\begin{equation}\n",
    "\t\\hat{H}[u(t)] = \\frac{E_0 u(t)}{2}\\,\\hat{\\sigma}_z,\n",
    "\\end{equation}\n",
    "where $E_0$ is a fixed energy scale, $u(t)$ is our single continuous control and $\\hat{\\sigma}_z$ denotes a Pauli matrix. The coupling to the single bath is described using the Lindblad master equation [see Eq. (9) of the manuscript]. The Lindblad operators and corresponding rates are gived by\n",
    "\\begin{align}\n",
    "\t\\hat{A}_{\\pm,u(t)} &= \\hat{\\sigma}_\\pm, & \\gamma_{\\pm,u(t)}  &= \\Gamma\\, f(\\pm\\beta u(t) E_0 ),\n",
    "\\end{align}\n",
    "where $\\hat{\\sigma}_+$ and $\\hat{\\sigma}_-$ are respectively the raising and lowering operator, $\\Gamma$ is a constant rate, $f(x) = (1+\\exp(x))^{-1}$ is the Fermi distribution and $\\beta$ is the inverse temperature of the bath.\n",
    "#### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join('..','src'))\n",
    "import sac\n",
    "import sac_envs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup New Training\n",
    "The following codes initiates a new training session. All training logs, parameters and saved states will be stored under the ```data``` folder, within a folder with the current date and time. \n",
    "- ```env_params``` is a dictionary with the environment parameters.\n",
    "- ```training_hyperparams``` is a dictionary with training hyperparameters.\n",
    "- ```log_info``` is a dictionary that specifices which quantities to log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_params = {\n",
    "    \"g0\": 1.,                        #\\Gamma of the bath\n",
    "    \"b0\": 1.,                        #inverse temperature \\beta of the bath\n",
    "    \"min_u\": 0.3,                    #minimum value of action u\n",
    "    \"max_u\": 1.,                     #maximum value of action u\n",
    "    \"e0\": 1,                         #E_0\n",
    "    \"dt\": 0.5,                       #timestep \\Delta t\n",
    "    \"reward_extra_coeff\": 1.         #the reward is multiplied by this factor\n",
    "}  \n",
    "training_hyperparams = {\n",
    "    \"BATCH_SIZE\": 256,              #batch size\n",
    "    \"LR\": 0.001,                    #learning rate\n",
    "    \"ALPHA_START\": 1.,              #initial value of SAC temperature\n",
    "    \"ALPHA_END\": 0.,                #final value of SAC temperature\n",
    "    \"ALPHA_DECAY\": 10000,           #exponential decay of SAC temperature\n",
    "    \"REPLAY_MEMORY_SIZE\": 192000,   #size of replay buffer\n",
    "    \"POLYAK\": 0.995,                #polyak coefficient\n",
    "    \"LOG_STEPS\": 1500,              #save logs and display training every number of steps\n",
    "    \"GAMMA\": 0.995,                 #RL discount factor\n",
    "    \"HIDDEN_SIZES\": (256,256),      #size of hidden layers \n",
    "    \"SAVE_STATE_STEPS\": 80000,      #saves complete state of trainig every number of steps\n",
    "    \"INITIAL_RANDOM_STEPS\": 5000,   #number of initial uniformly random steps\n",
    "    \"UPDATE_AFTER\": 1000,           #start minimizing loss function after initial steps\n",
    "    \"UPDATE_EVERY\": 50,             #performs this many updates every this many steps\n",
    "    \"USE_CUDA\": False               #use cuda for computation\n",
    "}\n",
    "log_info = {\n",
    "    \"log_running_reward\": True,     #log running reward \n",
    "    \"log_running_loss\": True,       #log running loss\n",
    "    \"log_actions\": True,            #log chosen actions\n",
    "    \"extra_str\": \"_two_level_heater\"#extra string to append to training folder\n",
    "}\n",
    "\n",
    "train = sac.SacTrain()\n",
    "train.initialize_new_train(sac_envs.TwoLevelHeater, env_params, training_hyperparams, log_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train \n",
    "Perform a given number of training steps. It can be run multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.train(500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the State\n",
    "The full state of the training session is saved every ```SAVE_STATE_STEPS``` steps. Run this command if you wish to manually save the current state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.save_full_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Existing Training\n",
    "Any training session that was saved can be loaded specifying the training session folder in ```log_dir```. This will produce a new folder for logging with the current date-time. The following loads the latest save in a folder named ```\"2021_04_14-11_03_52_two_level_heater\"```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"../data/2021_04_14-11_03_52_two_level_heater\"\n",
    "train = sac.SacTrain()\n",
    "train.load_train(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train \n",
    "Perform a given number of training steps. It can be run multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train.train(50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually changing the learning \n",
    "The following is NOT RECOMMENDED, since the change is not logged. However, it is possible to change the learning rate during training. The following changes the learning rate to 0.0001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in train.pi_optimizer.param_groups:\n",
    "    g['lr'] = 0.0001\n",
    "for g in train.q_optimizer.param_groups:\n",
    "    g['lr'] = 0.0001"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
